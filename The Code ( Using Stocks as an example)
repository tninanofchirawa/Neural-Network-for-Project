import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from scipy.special import factorial
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

# Function for combinatorial binomial series
def the_series(x, n, r):
    factr = factorial(r)
    i_vals = np.arange(n + 1)
    prdt = np.prod(i_vals[:, None] + np.arange(1, r + 1), axis=1)
    series = (prdt / factr) * (x ** i_vals)
    scaled_series = np.sum(series) / (1 + np.sum(series))  # Scale to prevent growth
    return scaled_series

# Fixed realistic stock prices over 10 days
fixed_stock_prices = np.array([100, 102, 101, 105, 107, 106, 104, 108, 110, 109, 111])

# Preprocess stock prices to compute percentage changes
def pre_data(stock_prices):
    """
    Compute percentage changes as observations.
    """
    perct_change = np.diff(stock_prices) / stock_prices[:-1] * 100
    return perct_change.reshape(-1, 1)  # Reshape for model compatibility

# Problem setup
N = 3  # Number of hidden states
n = 3  # Maximum degree of series
r = 2  # Number of terms in combinatorial product
T = len(fixed_stock_prices) - 1  # Number of observations
d = 1  # Dimension of observation vector

# Process the data
observations = pre_data(fixed_stock_prices)

# Transition probabilities (fixed for reproducibility)
A = np.array([[0.6, 0.3, 0.1],
              [0.2, 0.5, 0.3],
              [0.1, 0.4, 0.5]])

# Initial probabilities (fixed for reproducibility)
pi = np.array([0.5, 0.3, 0.2])

# Build a neural network for emission probabilities
mdl = Sequential([
    Dense(16, activation='relu', input_shape=(d,)),
    Dense(N, activation='softmax')  # Output size = number of hidden states
])
mdl.compile(optimizer='adam', loss='categorical_crossentropy')

# Cluster observations into N states for realistic training labels
kmeans = KMeans(n_clusters=N, random_state=42)
state_labels = kmeans.fit_predict(observations)

# One-hot encode the labels
trgt = np.eye(N)[state_labels]

# Train the neural network
mdl.fit(observations, trgt, epochs=50, verbose=1)

# Function to compute emission probabilities
def emi_prob(obs):
    nn_output = mdl.predict(obs, verbose=0)  # Neural network predictions
    emis = []
    for state_idx in range(N):
        state_probs = nn_output[:, state_idx]
        emis.append([
            the_series(state_probs[t], n, r) for t in range(len(obs))
        ])
    return np.array(emis).T  # Shape: (T, N)

# Forward algorithm with normalization
def for_algo(obs, verbose=False):
    B = emi_prob(obs)  # Emission probabilities (T x N)
    alpha = np.zeros((len(obs), N))
    # Initialization
    alpha[0, :] = pi * B[0, :]
    alpha[0, :] /= np.sum(alpha[0, :])  # Normalize
    if verbose:
        print(f"Initial alpha (normalized):\n{alpha[0, :]}")
    # Recursion
    for t in range(1, len(obs)):
        alpha[t, :] = B[t, :] * np.dot(alpha[t - 1, :], A)
        alpha[t, :] /= np.sum(alpha[t, :])  # Normalize
    return alpha

# Backward algorithm
def back_algo(obs, verbose=False):
    B = emi_prob(obs)  # Emission probabilities (T x N)
    beta = np.zeros((len(obs), N))
    # Initialization
    beta[-1, :] = 1
    # Recursion
    for t in range(len(obs) - 2, -1, -1):
        beta[t, :] = np.dot(A, (B[t + 1, :] * beta[t + 1, :]))
        beta[t, :] /= np.sum(beta[t, :])  # Normalize
    return beta

# Compute forward and backward probabilities
alpha = for_algo(observations, verbose=True)
beta = back_algo(observations, verbose=False)

# Compute smoothed probabilities
def compute_smoothed_probs(alpha, beta):
    smoothed = alpha * beta  # Element-wise multiplication
    smoothed /= np.sum(smoothed, axis=1, keepdims=True)  # Normalize
    return smoothed

smoothed_probs = compute_smoothed_probs(alpha, beta)

# Likelihood of the observation sequence
likelihood = np.sum(alpha[-1, :])

# Plot results
plt.figure(figsize=(12, 6))

# Plot stock prices
plt.subplot(2, 1, 1)
plt.plot(fixed_stock_prices, label='Stock Prices', color='blue', marker='o')
plt.title('Fixed Stock Prices')
plt.xlabel('Time Steps')
plt.ylabel('Price')
plt.legend()

# Plot smoothed probabilities for each state
plt.subplot(2, 1, 2)
for state in range(N):
    plt.plot(smoothed_probs[:, state], label=f'State {state + 1}')
plt.title('Smoothed Probabilities for Hidden States')
plt.xlabel('Time Steps')
plt.ylabel('Probability')
plt.legend()
plt.tight_layout()
plt.show()

# Print results
print("Likelihood of observations:", likelihood)
